{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Sourajit-Maity/juvdv2-vdvwc.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Define the source and destination paths\nsource_folder = '/kaggle/working/juvdv2-vdvwc/Val'\ndestination_folder = '/kaggle/working/juvdv2-vdvwc/images/'\n\n# Copy the entire folder\nshutil.move(source_folder, destination_folder)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd \"/kaggle/working/juvdv2-vdvwc\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir images labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define the current and new folder names\ncurrent_folder = '/kaggle/working/juvdv2-vdvwc/Annotation'\nnew_folder = '/kaggle/working/juvdv2-vdvwc/labels'\n\n# Rename the folder\nos.rename(current_folder, new_folder)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nfrom ultralytics import YOLO\nfrom PIL import Image, ImageEnhance\n\n# Define weather-specific preprocessing functions\ndef preprocess_image(image_path, label):\n    image = cv2.imread(image_path)\n    if 'Rainny' in label:\n        image = denoise_image(image)\n    if 'Night' in label:\n        image = enhance_image(image)\n    return image\n\ndef enhance_image(image):\n    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    enhancer = ImageEnhance.Brightness(pil_image)\n    enhanced_image = enhancer.enhance(1.5)  # Increase brightness\n    return cv2.cvtColor(np.array(enhanced_image), cv2.COLOR_RGB2BGR)\n\ndef denoise_image(image):\n    denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n    return denoised_image\n\ndef preprocess_annotations(annotation_path, image_shape):\n    with open(annotation_path, 'r') as file:\n        annotations = file.readlines()\n    \n    processed_annotations = []\n    for annotation in annotations:\n        parts = annotation.strip().split()\n        try:\n            class_index = int(parts[0])  # YOLO class index\n            x_center = float(parts[1])\n            y_center = float(parts[2])\n            width = float(parts[3])\n            height = float(parts[4])\n        except ValueError as e:\n            print(f\"Error parsing annotation {annotation} in file {annotation_path}: {e}\")\n            continue\n        \n        # Convert YOLO format to box coordinates (x_min, y_min, x_max, y_max)\n        x_min = int((x_center - width / 2) * image_shape[1])\n        y_min = int((y_center - height / 2) * image_shape[0])\n        x_max = int((x_center + width / 2) * image_shape[1])\n        y_max = int((y_center + height / 2) * image_shape[0])\n        \n        processed_annotations.append([x_min, y_min, x_max, y_max, class_index])\n    \n    return processed_annotations\n\n# Load image paths\ndef load_image_paths(root_folder):\n    image_paths = []\n    for folder in ['Train', 'Val']:\n        for weather in ['Rainny', 'Sunny']:\n            for time_of_day in ['Day', 'Night']:\n                image_folder = os.path.join(root_folder, 'images', folder, weather, time_of_day)\n                for file in os.listdir(image_folder):\n                    if file.endswith('.jpg') or file.endswith('.png'):\n                        image_paths.append(os.path.join(image_folder, file))\n    return image_paths\n\n# Load annotation paths\ndef load_annotation_paths(root_folder):\n    annotation_paths = []\n    for folder in ['Train', 'Val']:\n        for weather in ['Rainny', 'Sunny']:\n            for time_of_day in ['Day', 'Night']:\n                annotation_folder = os.path.join(root_folder, 'labels', folder, weather, time_of_day)\n                for file in os.listdir(annotation_folder):\n                    if file.endswith('.txt') and file != 'train.txt':\n                        annotation_paths.append(os.path.join(annotation_folder, file))\n    return annotation_paths\n\n# Preprocess and save images and annotations\ndef preprocess_and_save(root_folder):\n    image_paths = load_image_paths(root_folder)\n    annotation_paths = load_annotation_paths(root_folder)\n\n    for img_path, annot_path in zip(image_paths, annotation_paths):\n        label = os.path.basename(os.path.dirname(os.path.dirname(img_path)))  # Extract label from folder name\n        image = preprocess_image(img_path, label)\n        annotations = preprocess_annotations(annot_path, image.shape)\n\n        # Save preprocessed images and annotations\n        cv2.imwrite(img_path, image)\n        with open(annot_path, 'w') as file:\n            for annot in annotations:\n                file.write(f\"{annot[4]} {annot[0]} {annot[1]} {annot[2]} {annot[3]}\\n\")\n                \ndef compute_metrics(predictions, ground_truths):\n    # Convert predictions and ground truths to the format expected by sklearn\n    y_true, y_pred = [], []\n    for gt, pred in zip(ground_truths, predictions):\n        y_true.append(gt[4])\n        y_pred.append(pred[4])\n\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n    ap = average_precision_score(y_true, y_pred)\n    return precision, recall, f1, ap\n\ndef evaluate_model(model, dataloader):\n    predictions, ground_truths = [], []\n    for batch in dataloader:\n        images, targets = batch\n        outputs = model(images)\n        predictions.extend(outputs)\n        ground_truths.extend(targets)\n\n    precision, recall, f1, ap = compute_metrics(predictions, ground_truths)\n    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, Average Precision (AP): {ap:.4f}\")\n\n# YOLOv8s model training and evaluation\ndef main():\n    # Set paths and parameters\n    root_folder = '/kaggle/working/juvdv2-vdvwc'  # Update with your dataset root folder path\n    batch_size = 16\n    epochs = 2\n    input_shape = (416, 416)  # Assuming input image size for YOLOv8\n\n    # Preprocess and save data\n    preprocess_and_save(root_folder)\n\n    # Initialize YOLOv8 model from Ultralytics\n    model = YOLO('yolov8s.pt')  # Load the pre-trained YOLOv8s model\n\n    # Train the model using the dataset configuration\n    model.train(data=f'{root_folder}/dataset.yaml', epochs=epochs, batch=batch_size, imgsz=input_shape, device=[0,1])\n\n    # Save the trained model\n    model.save('enhanced_yolov8_vehicle_detection_model.pt')\n    \n    # Evaluate the model\n    val_dataloader = model.dataloader(val=True)  # Load validation data\n    evaluate_model(model, val_dataloader)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T04:09:34.155156Z","iopub.execute_input":"2024-07-12T04:09:34.156043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_yaml = \"\"\"\npath: /kaggle/working/juvdv2-vdvwc\ntrain: /kaggle/working/juvdv2-vdvwc/images/Train\nval: /kaggle/working/juvdv2-vdvwc/images/Val\n\nnc: 14  # number of classes\nnames: ['car', 'bike', 'auto', 'rickshaw', 'cycle', 'bus', 'minitruck', 'truck', 'van', 'taxi', 'motorvan', 'toto', 'train', 'boat']\n\"\"\"\nwith open('/kaggle/working/juvdv2-vdvwc/dataset.yaml', 'w') as f:\n    f.write(dataset_yaml)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}